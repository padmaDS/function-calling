from flask import Flask, request, jsonify
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema.runnable import RunnablePassthrough
from langchain.prompts import PromptTemplate
import os
import chromadb
from dotenv import load_dotenv
import json
import openai
from openai import OpenAI

# Load API keys
load_dotenv()

# Set OpenAI API key
api_key = os.getenv('OPENAI_API_KEY')

client = OpenAI(api_key=api_key)

# Define custom functions
custom_functions = [
        {
        'name': 'action_form',
        'description': 'Handles queries related to booking appointments, blocking apartments, contact sales, or contact details or enquiry about other projects.',
        'parameters': {
            'type': 'object',
            'properties': {
                'status': {
                    'type': 'string',
                    'description': 'Status of the result, indicating success or failure.'
                },
                'type': {
                    'type': 'string',
                    'description': 'Static type indicating "form" for form-related queries.',
                    'enum': ['form']  # This makes sure the type is always "form"
                }
            }
        }
    }

    ,
        {
        'name': 'action_showDocument',
        'description': 'Handles queries related to documents or brochures.',
        'parameters': {
            'type': 'object',
            'properties': {
                'status': {
                    'type': 'string',
                    'description': 'Status of the result, indicating success or failure.'
                },
                'type': {
                    'type': 'string',
                    'description': 'Static type indicating "showDocument" for document-related queries.',
                    'enum': ['showDocument']  # This makes sure the type is always "showDocument"
                }
            }
        }
    },

        {
        'name': 'action_knowledgebase',
        'description': 'Handles queries and returns responses based on the RAG chain.',
        'parameters': {
            'type': 'object',
            'properties': {
                'answer': {
                    'type': 'string',
                    'description': 'The response generated by fetching results.'
                },
                'type': {
                    'type': 'string',
                    'description': 'Type indicating "general" for general queries.',
                    'enum': ['knowledgebase']  # Ensure the type is always "" for this function
                }
            }
        }
    },
    {
        'name': 'action_other_projects',
        'description': 'Handles queries about other project related enquiries',
        'parameters': {
            'type': 'object',
            'properties': {
                'answer': {
                    'type': 'string',
                    'description': 'The response generated by fetching results.'
                },

                'type': {
                    'type': 'string',
                    'description': 'Static type indicating "project_link" for other project related queries.',
                    'enum': ['project_link']  # Ensure the type is always "" for this function
                }
            }
        }
    }

]
# Initialize RAG (for action_general)
embeddings = OpenAIEmbeddings()

# Load documents from directory
directory = 'data'
loader = DirectoryLoader(directory)
data = loader.load()

# Split documents into chunks
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
docs = text_splitter.split_documents(data)

# Create an ephemeral Chroma client
new_client = chromadb.EphemeralClient()

# Initialize Chroma vector store with the documents and embeddings
vector_db = Chroma.from_documents(
    docs, embeddings, client=new_client, collection_name="purvankara"
)

# Initialize OpenAI language model
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# Set up the retriever
retriever = vector_db.as_retriever()

# Define the prompt template
template = """You are an Intelligent Indian Real Estate customer service AI Assistant.
    You are designed to respond to answers as per the input language regarding the Provident Park Square, it is a world-class residential project.
    You are primarily programmed to communicate in English. However, if user asks in another language,
    you must strictly respond in the same language as the userâ€™s language. Do not respond in English for other language queries.
    - Provide the response with more professional and personalized in a good customer service oriented fashion.
   - Always provide address and map location when asked about the location details in any language.

{context}

Question: {question}
Helpful Answer:"""
rag_prompt = PromptTemplate.from_template(template)

# Define the RAG chain
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | rag_prompt
    | llm
)

# Flask app setup
app = Flask(__name__)

# Function to handle action_general queries
def ask(question):
    response = rag_chain.invoke(question)
    return response.content

# Function to call OpenAI API

def get_openai_response(query, custom_functions):
    try:
        response = client.chat.completions.create(
            model='gpt-4o-mini',  # Replace with the appropriate model name if needed
            messages=[{'role': 'user', 'content': query}],
            functions=custom_functions,
            function_call='auto'
        )
        
        # Extract the function call details
        function_call = response.choices[0].message.function_call
        function_name = function_call.name
        function_arguments = json.loads(function_call.arguments)

        return {"function_name": function_name, "arguments": function_arguments}

    except Exception as e:
        return {"error": str(e)}


# Flask route to handle queries
@app.route('/purvankara', methods=['POST'])
def handle_query():
    query = request.json.get('query')
    
    # Call OpenAI completion with custom functions
    openai_response = get_openai_response(query, custom_functions)

    # Parse the response
    function_name = openai_response.get('function_name')
    json_response = openai_response.get('arguments', {})

    # Handle different functions based on the type
    if function_name == 'action_form':
        # Ensure the type is "form" and handle accordingly
        json_response['type'] = 'form'
        return jsonify(json_response)
    
    elif function_name == 'action_showDocument':
        # Ensure the type is "showDocument" and handle accordingly
        json_response['type'] = 'showDocument'
        return jsonify(json_response)
    
    elif function_name == 'action_other_projects':
        # Ensure the type is "project_link" and handle accordingly
        json_response['type'] = 'project_link'
        # answer = ask(query)
        # return jsonify({"answer": answer, "type":"project_link"})
        json_response['answer'] = ask(query)

        return jsonify(json_response)
    
    elif function_name == 'action_knowledgebase':
        # Call RAG chain for general queries
        answer = ask(query)
        return jsonify({"answer": answer})

       # return jsonify({"answer": answer, "type": "knowledgebase"})

    return jsonify({"status": "No valid action detected"})


# Run the Flask app
if __name__ == '__main__':
    app.run(debug=True)
